---
title: "10-数据科学与R：探索性数据分析EDA"
author: "王梓安"
date: "2025-03-12"
output:
  rmarkdown::html_document:
    toc: true # 开启目录
    toc_depth: 6 # 目录深度
    toc_float: true # 让目录浮动在左侧
    number_sections: false # 不自动生成目录
    code_download: true # 启用一键下载功能
    theme: cerulean
    highlight: pygments
    css: custom.css # 添加自定义CSS文件
    includes:
      in_header: header.html # 引入自定义HTML/JS文件
---

在前面的章节中，主要回顾了一些传统统计学的基本概念、R语言的基础用法和对数据科学进行了一些初探。

事实上，回归等概念也属于传统统计学的概念，但是其中的拟合之类的说法让我感觉其更接近于数据科学的范畴，因此我觉得将其放在数据科学的范畴内更为合适，因此前面并未曾涉及。

但是，不可否认的是，传统统计学和数据科学的关系是密不可分的，因此，我才会把统计学基础的学习置于数据科学之前；但是，如果不明白这些学科之间的差别，那也就无法搞清研究的意义和实际价值；故在开始系统地学习统计学和数据科学之前，有必要明确不同但相关的学科之间到底存在怎样的关系：

**概率论是统计学的数学基础，与概率论的纯理论本质不同，统计学是一门应用科学，关注的是数据的分析和建模；不少统计学概念在很大程度上深深地植根于数据科学中**。我们既需要学习、理解这些统计学概念，也需要明白这些统计学概念在数据科学和大数据的背景下是否依然重要。

本章的重点是探索数据，这是所有数据科学项目的第一步。探索性数据分析（EDA）是统计学中一个相对新的领域。经典统计学几乎只注重推断，即从小样本得出关于整体数据的结论，这往往是一个复杂的过程。而随着计算能力和数据分析软件可用性的提高，探索性数据分析的发展已远超其最初的范围。

## 引入-数据的分布特征

在对数据进行探索之前，我们需要了解数据有哪些描述性的特征。而衡量一组数据的分布时，我们通常关注以下几个方面的指标：

### 1. 集中趋势（Central Tendency）

这类指标反映数据集中在某个位置的趋势，即数据的“中心”在哪里。常见的集中趋势指标有：

-   **均值（Mean）**：数据的算术平均数，是所有数据值的总和除以数据点的个数。

-   **中位数（Median）**：将数据排序后位于中间的值。当数据分布存在偏态时，中位数能比均值更好地表示数据的中心。

-   **众数（Mode）**：数据集中出现频率最高的值，适用于类别型数据或有多个重复值的数据集。

### 2. 离散程度（Dispersion）

这类指标用于描述数据的分散或变异程度。常见的离散程度指标有：

-   **方差（Variance）**：数据每个值与均值差异的平方的平均值。方差越大，表示数据的离散程度越高。

-   **标准差（Standard Deviation）**：方差的平方根，和原始数据单位相同，比方差更容易解释。

-   **极差（Range）**：数据中最大值与最小值之差，能反映数据的最大波动范围。

-   **四分位差（Interquartile Range, IQR）**：上四分位数与下四分位数之差，描述数据中间50%的变动范围，能有效抵抗极端值的影响。

### 3. 形态（Shape）

这类指标反映数据分布的形状，常见的指标包括：

-   **偏度（Skewness）**：衡量数据分布的不对称性。正偏（右偏）表示数据右侧尾巴长，负偏（左偏）表示数据左侧尾巴长。

-   **峰度（Kurtosis）**：衡量数据分布的尖峭程度。高峰度表示数据分布比正态分布更尖锐，低峰度则表示分布更平缓。

### 4. 分布特征

这类指标描述数据如何分布，常见的有：

-   **分位数（Quantiles）**：将数据分成若干等分点，常见的有四分位数（Q1, Q2, Q3），分位数能提供数据分布的详细信息。

-   **箱线图（Boxplot）**：通过最小值、第一四分位数、中位数、第三四分位数和最大值的可视化，展示数据分布的概况。

### 5. 数据的对称性与正态性

-   **正态性检验**：检验数据是否近似呈正态分布。常用的检验方法有 Shapiro-Wilk 检验、Kolmogorov-Smirnov 检验等。

## 10.1 EDA简介

EDA并不是一蹴而就的单向流程，恰恰相反，对数据集有充分认识之后，你很可能需要回头重做一个或多个数据处理任务，更进一步地对数据进行提纯或转换；EDA的另一个附加好处是对特征集合进行精炼，以用于后面的机器学习中：**一旦完成了探索性数据分析步骤，你应该有一个确定的特征集，供监督和非监督统计学习使用**（不管这个特征集是否后续还需要进行进一步的EDA探索）。

在EDA中，有一种不太常用的图表是饼图，因为它涉及角度比较（判断扇形图的相对大小）。比起其他图表类型（例如，柱状图和箱型图）的位置比较，饼图通常更难以解释。3D柱状图也不常用，因为比较体积也是很困难的。

**EDA探索主要的几个方面如下：**

### 1.了解数据基本结构

**目的：**

-   了解数据的整体情况，如变量类型、数值范围、缺失值情况。

-   判断数据是否需要预处理（去除异常值、填充缺失值）。

+--------------------------+--------------------+---------------------------------+------------------------------------------------+
| **要回答的问题**         | **需要检查的指标** | **推荐方法**                    | **可能的结论与影响**                           |
+==========================+====================+=================================+================================================+
| 这个数据集中有哪些变量？ | 变量名称、数据类型 | `str(df)`                       | 确定变量类型（数值型/类别型）是否符合预期。    |
|                          |                    |                                 |                                                |
|                          |                    | `glimpse(df)`                   |                                                |
+--------------------------+--------------------+---------------------------------+------------------------------------------------+
| 每个变量的取值范围？     | 均值、中位数、极值 | `summary(df)`                   | 识别异常值、偏态数据，决定是否归一化或标准化。 |
|                          |                    |                                 |                                                |
|                          |                    | `describe(df)`                  |                                                |
|                          |                    |                                 |                                                |
|                          |                    | `mean(df$变量`                  |                                                |
|                          |                    |                                 |                                                |
|                          |                    | `na.rm=TRUE)`                   |                                                |
|                          |                    |                                 |                                                |
|                          |                    | `min(df$变量)`                  |                                                |
|                          |                    |                                 |                                                |
|                          |                    | `max(df$变量)`                  |                                                |
|                          |                    |                                 |                                                |
|                          |                    | `range(df$变量)`                |                                                |
|                          |                    |                                 |                                                |
|                          |                    | `quantile(df$变量, na.rm=TRUE)` |                                                |
+--------------------------+--------------------+---------------------------------+------------------------------------------------+
| 数据有缺失值吗？         | 缺失值占比         | `sum(is.na(df))`                | 如果缺失比例过高，考虑填充或删除变量。         |
|                          |                    |                                 |                                                |
|                          |                    | `sum(!is.na(df$变量))`          |                                                |
|                          |                    |                                 |                                                |
|                          |                    | `vis_miss(df)`                  |                                                |
+--------------------------+--------------------+---------------------------------+------------------------------------------------+
| 变量的特殊值有哪些？     | 唯一值             | `unique(df$变量)`               | 了解变量的取值范围，识别异常值。               |
+--------------------------+--------------------+---------------------------------+------------------------------------------------+

**结论如何影响后续分析？**

-   **变量类型决定分析方式**（如类别变量不能用线性回归）。

-   **数值分布决定标准化或归一化的必要性**（如极值影响模型稳定性）。

-   **缺失值填充策略影响数据质量**（如均值填充 vs. 预测填充）。

### 2.了解数据分布

**目的：**

-   观察变量的偏态、是否服从正态分布。

-   决定是否需要变换数据（如对数变换、Box-Cox 变换）。

| **要回答的问题** | **需要检查的指标** | **推荐方法** | **可能的结论与影响** |
|----|----|----|----|
| 变量的分布形态如何？ | 直方图、密度图 | `hist(df$变量)`、`density(df$变量)` | 识别是否需要转换数据，如对数变换调整偏态。 |
| 变量是否服从正态分布？ | QQ 图、Shapiro-Wilk 检验 | `qqnorm(df$变量)`、`shapiro.test(df$变量)` | 线性模型假设正态性，若偏离严重，考虑变换数据。 |
| 数据是否存在偏态？ | 偏度、峰度 | `skewness(df$变量)`、`kurtosis(df$变量)` | 偏态大的数据可能影响统计检验和模型预测。 |

**结论如何影响后续分析？**

-   **数据偏态影响建模**（如回归分析假设正态性）。

-   **非正态分布数据可能影响假设检验的有效性**（如 t 检验要求正态性）。

-   **数据转换可以改善模型效果**（如对数变换降低数据跨度）。

### ️3.发现异常值

**目的：**

-   识别可能的数据录入错误或极端值。

-   决定是否剔除异常值，或在建模时进行处理。

+--------------------------+-------------------------+--------------------------------------+--------------------------------------------------------+
| **要回答的问题**         | **需要检查的指标**      | **推荐方法**                         | **可能的结论与影响**                                   |
+==========================+=========================+======================================+========================================================+
| 数据中是否存在极端值？   | 箱形图、Z-score         | `boxplot(df$变量)`、`scale(df$变量)` | 发现离群值，决定是否剔除或用其他方法替换。             |
+--------------------------+-------------------------+--------------------------------------+--------------------------------------------------------+
| 这些异常值是否影响分析？ | 均值 vs. 中位数、标准差 | `mean(df$变量) vs. median(df$变量)`  | 极端值影响均值，可能导致误导性分析结果。               |
|                          |                         |                                      |                                                        |
|                          |                         | `sd(df$变量)`                        |                                                        |
+--------------------------+-------------------------+--------------------------------------+--------------------------------------------------------+
| 是否需要处理异常值？     | Z-score \> 3 的数据点   | `df[abs(scale(df$变量)) > 3, ]`      | 可能的数据录入错误，或者本身是重要发现（如欺诈检测）。 |
+--------------------------+-------------------------+--------------------------------------+--------------------------------------------------------+

**结论如何影响后续分析？**

-   **异常值影响均值和回归模型**（如 OLS 受异常值影响较大）。

-   **可考虑使用稳健统计方法**（如中位数回归）。

-   **异常值可能是关键信息**（如信用卡欺诈检测中的异常交易）。

### 4.变量之间的关系

**目的：**

-   识别变量之间的相关性，为特征选择提供依据。

-   观察变量间是否存在线性或非线性关系。

| **要回答的问题** | **需要检查的指标** | **推荐方法** | **可能的结论与影响** |
|----|----|----|----|
| 变量之间是否有相关性？ | 相关矩阵 | `cor(df)`、`heatmap(cor(df))` | 发现冗余变量，避免多重共线性。 |
| 变量之间的关系是线性还是非线性？ | 散点图 | `plot(df$变量1, df$变量2)` | 线性关系适合回归，非线性关系可能需要多项式或其他建模方法。 |
| 目标变量与特征变量是否相关？ | 目标变量 vs. 其他变量的相关性 | `cor(df$目标变量, df$特征变量)` | 低相关性可能意味着该特征无助于预测，应考虑删除。 |

**结论如何影响后续分析？**

-   **避免多重共线性问题**（如高相关变量会影响回归模型）。

-   **非线性关系可能需要变换或使用更复杂的模型**（如决策树、神经网络）。

-   **低相关变量可能无助于建模**（可以通过特征选择剔除）。

### 5.处理缺失值

**目的：**

-   识别数据缺失模式，决定填充或删除方式。

| **要回答的问题** | **需要检查的指标** | **推荐方法** | **可能的结论与影响** |
|----|----|----|----|
| 数据缺失是否有模式？ | 缺失值分布 | `vis_miss(df)`、`md.pattern(df)` | 若为随机缺失（MCAR），可以直接删除；若非随机，需要填充。 |
| 是否可以填充缺失值？ | 均值、中位数、插值 | `df$变量[is.na(df$变量)] <- mean(df$变量, na.rm=TRUE)` | 取决于缺失的数量和分布。 |
| 缺失值是否影响建模？ | 缺失值比例 | `sum(is.na(df))/nrow(df)` | 若缺失值占比过高，可能影响模型稳定性。 |

**结论如何影响后续分析？**

-   **随机缺失可直接删除**，但可能损失部分信息。

-   **模式化缺失可能影响建模**（如低收入人群可能更倾向于不填写收入）。

-   **填充方式影响数据质量**（如均值填充可能低估数据方差）。

### 6. 统计/聚合分析

| **要回答的问题** | **需要检查的指标** | **推荐方法（R 代码）** | **可能的结论与影响** |
|----|----|----|----|
| 变量中特定值的数量？ | 计数 | `sqldf("select count(Ozone) from airquality where Ozone=11")` | 统计某个值的出现次数，发现异常情况。 |
| 计算方差 | 数据离散程度 | `var(df$变量)`, `sd(df$变量)` | 方差较大说明数据点与均值相差远。 |
| 数据预览 | 前几行/后几行 | `head(df)`, `tail(df)` | 快速了解数据内容。 |
| 因子变量的类别 | 类别分布 | `levels(df$因子变量)` | 检查分类变量的可能值，发现数据质量问题。 |

1.  **变量中特定值的数量**

    -   **适用场景**：用于检查数据是否存在某些特定值的过多或过少情况，如异常值检测。

    -   **后续影响**：如果某个值出现次数远超其他值，可能表示数据分布不均，或者该值有特殊含义，需要重新编码或进行分箱。

2.  **计算方差**

    -   **适用场景**：用于判断数据的离散程度，若方差过大，说明数据波动剧烈。

    -   **后续影响**：高方差的数据可能影响建模稳定性，需进行标准化或使用稳健统计方法（如中位数回归）。

3.  **数据预览**

    -   **适用场景**：在数据探索的第一步，快速获取数据的结构和内容。

    -   **后续影响**：如果发现某些变量格式异常或存在大量缺失值，可能需要在正式分析前进行数据预处理。

4.  **因子变量的类别**

    -   **适用场景**：用于检查分类变量的类别是否合理，如性别（Male/Female）是否有拼写错误（如 `M` / `Male`）。

    -   **后续影响**：如果分类变量中存在不合理的类别，可能会影响分组分析和机器学习模型的效果，需要重新编码或合并类别。

## 10.2 数据统计

### 1 识别不重复元素：unique函数

对一名数据科学家来说，希望在数据集中执行的第一种探索形式是数据统计或聚合。**熟悉一个特殊值在变量中出现的次数通常来说是有帮助的：**

例如，使用airquality数据集，让我们看看Month变量中所有的特殊值。为此，我们可以使用R中的unique()函数；这个函数将变量作为参数传递，能返回所有的特殊值。

```{r eval=FALSE}
airquality
# unique() 是一个函数，用于返回向量中不重复的元素，当某些元素反复出现（5,5,5,5,5,5,6,6,6,6,6,7,7,7,7,7,……）时，可以使用unique函数识别出这些对象中具体有几个元素并返回（5,6,7）。
unique(airquality$Month)
```

### 2 对特定值进行数量统计：sqldf函数

你可能也想对数据集中某个变量的某个特殊值进行数量统计。虽然在R中有很多方法能实现这一目标，这次我们将使用第2章详细介绍过的sqldf包。用下面的SQL语句能获得某个值的数量：在这个例子中，表示 `airquality` 数据集中 `Ozone` 列的值等于 `11` 的记录有多少条。

```{r eval=FALSE}
library(sqldf)
# select count(Ozone)：这是 SQL 查询中的计数操作，它返回 Ozone 列中等于 11 的行数。
# from airquality：这是查询数据源，表示从 airquality 数据集中获取数据。
# where Ozone=11：这是 SQL 的条件语句，筛选出 Ozone 列中等于 11 的记录。
sqldf("select count(Ozone) from airquality where Ozone=11")
```

### 3 数据的分布特征概览

#### 1.summary函数（集中、离散指标）

summary()能检查整个数据集，并提供每个数值变量的众多统计数据：最小值、最大值、平均值、中位数、第一四分位数和第三四分位数。对于因子变量来说，summary()能给出最常出现的值的数目（低频数值的数目在“Other”分类中）。

```{r eval=FALSE}
summary(airquality)
```

#### 2.具体问题具体分析（集中、离散指标）

在具体的定量变量上，其他的一些R函数可以执行summary()的大部分功能：

-   mean()可以计算算术平均值

-   min()能找到最小值

-   max()能找到最大值

-   range()返回一个包含最小值和最大值的数组

-   quantile()可以用于计算最小值、第一四分位数、中位数、第三四分位数和最大值

注意：我们在这些函数中加入了参数na.rm=TRUE，用于忽略所有NA的值。

```{r eval=FALSE}
mean(airquality$Ozone, na.rm=TRUE)
min(airquality$Wind)
max(airquality$Solar.R, na.rm=TRUE)
range(airquality$Month)
quantile(airquality$Ozone, na.rm=TRUE)
```

#### 3.方差度量：var函数（离散指标）

方差是一个统计量，用于展示定量数据值偏离平均值的程度：

-   如果方差为0，说明所有的值都相同。方差总是非负的。

-   若方差很小，说明数据点与平均值都很接近，也就是说，数据值彼此都很接近；若方差较大，说明数据点与平均值相差很远，换句话说，数据点彼此之间相差很远。

-   方差的算数平方根称为标准差。

让我们用airquality数据集来计算几个方差：第一个例子展示了变量Temp的方差，第二个例子展示了去除所有的NA值之后、变量Ozone的方差。

```{r eval=FALSE}
var(airquality$Temp)
var(airquality$Ozone, na.rm=TRUE)
```

### 4 预览：head和tail函数

R中也有head()和tail()函数，分别能够快速展示数据集中前6行和后6行记录。这既能快速获得对数据的感觉，又不会花费太多时间。**面对一个全新的数据集时，这很可能是你要做的第一个检查**。

```{r eval=FALSE}
head(airquality)
```

### 5 因子的水平测度：level函数

很多数据集中含有类变量，它们的值可能是“男”或“女”，而不是数值。在R中，这些变量称作“因子”变量。对于大多数因子变量，你要做的一项很重要的探索性工作就是，查看这些变量中包含哪些值。

可以用R中的levels()函数来达到这一目标。为了演示这项特性，我们用ToothGrowth数据集中的supp变量作为例子：

```{r eval=FALSE}
levels(ToothGrowth$supp)
```

### 6 了解和统计缺失数据

在探索一个数据集时，了解某个变量有多少无缺失数据通常是很有用的。在这里展示3种方法，其中，最后一种最简便：

```{r eval=FALSE}
length(airquality$Ozone[is.na(airquality$Ozone) == FALSE])
length(airquality$Ozone[!is.na(airquality$Ozone)])
sum(!is.na(airquality$Ozone))
```

## 10.3 探索可视化

| **情境** | **数据类型** | **推荐 EDA 方法** | **工具函数** |
|----|----|----|----|
| **理解数据基本统计** | 数值型 / 分类变量 | 计算均值、中位数、众数、标准差、极值 | `summary()`、`describe()` |
| **查看数据分布** | 数值型变量 | 直方图、密度图、QQ 图 | `hist()`、`density()`、`qqnorm()` |
| **检查离群点** | 数值型变量 | 箱形图（Boxplot） | `boxplot()` |
| **变量间关系** | 数值型变量 | 散点图（查看线性相关性）、相关矩阵 | `plot()`、`cor()` |
| **类别变量分布** | 分类变量 | 条形图（Bar Chart） | `barplot()` |
| **数据分布概览** | 大量变量 | 热图（Heatmap） | `heatmap()` |
| **检查数据缺失情况** | 任意变量 | 缺失值可视化 | `vis_miss()`（`naniar` 包）、`mice` |

探索性图表（exploratory plot）能指引你做一些初期的决定：如何最好地在机器学习中使用你的数据、选择哪种模型。探索性图表很快完成，通常不必考虑它们是如何创造出来的，只要能将重要的信息传达给数据科学家就可以了。把这些图表当作是供后面使用的“草稿”，最后进行分析。

这些图表的目标是为个人理解带来帮助，不必用这些图表跟别人交流。所以在这个时候别纠结于使用哪些颜色、标题、图例、坐标轴标签等，在探索性阶段，美学不重要。

### 1 直方图

在执行EDA时，理解数据集的分布形状十分重要。数据的分布能告诉你数据中是否有异常值，某个机器学习算法是否适合这个数据集，或者仅仅只是让你知道某个数值范围内有多少观测值。

一个单变量的频度图，也就是直方图，很简单但是对于快速了解某个变量的值是如何分布的有很大帮助。

在iris数据集的帮助下，我们将使用一个直方图对Sepal.Length变量进行探究：

```{r eval=FALSE}
# 展示了变量Sepal.Length中每个值出现的频率。
hist(iris$Sepal.Length)
```

现在让我们看看另一种直方图的形式，它可以展示值的密度分布。我们将使用hist()函数，参数probability=TRUE。

这种形式的直方图显示了值的密度而不是频率：密度可以看做是所有观测中某个值出现的百分比。

```{r eval=FALSE}
# 在直方图中，你可以用参数breaks对间隔的数目进行规定，从而改变显示时的间隔尺寸。
# 用lines()和density()函数添加一条平滑的线，展示分布的密度。
hist(iris$Sepal.Length, probability=TRUE, breaks=10)
lines(density(iris$Sepal.Length))
```

### 2 箱形图

箱形图对定量变量尤其有用。

#### 1.对单一特征或一组特征

下面的例子使用了airquality数据集中的Ozone变量，用boxplot()函数进行绘图：将定量变量作为参数传递，同时设置col=“blue”，这样能使箱形图的箱体部分不再是黑色，更便于与图表的其他部分区分开来。

```{r eval=FALSE}
boxplot(airquality$Ozone, col="blue")
```

箱形图可以表示多个不同数值：

-   在箱体中央的粗黑线代表了中位数，或者是分布的中心（在图中展示的数值是31.5）；中位数又被称为第二四分位数（Q2）

-   箱体的上下界分别代表了数据的第三（Q3）和第一（Q1）四分位数。矩形从上到下的长度指的是四分位差（IQR）。

-   从箱体中纵向延伸出来的线称为“触须”：上方的触须表示第三四分位数加上1.5倍的IQR；下方的触须表示第一四分位数加上1.5倍的IQR。

-   有一些数据点游离在上方触须之外，这些表示的是极端值（同样，极端值也会出现在下触须的下方）。

#### 2.对多个特征或多组特征

在箱型图中，可以在同一图表中绘制多个箱型图，每个箱型图表示一个变量或组别的数据分布情况。这样，你可以直接比较这些组别之间的数据分布、位置（中位数）、变异性（四分位数间距）以及异常值。对比多个或多组特征，所有箱型图采用相同的尺度和坐标系，这样便于不同组别的数据分布直接对比。

通过这种比较，我们可以获得类似于双样本t检验和单向方差分析的结果，这些方法通常用于检验不同组之间是否存在显著差异。在箱型图中，组与组之间的差异可以通过比较中位数的位置和四分位数间距的大小来进行初步判断。

如下图所示。可以看到OJ中len特征的中位数比VC中的要高。所以，通过把箱形图放在同一尺度下，你可以比较分布的中心和变化。

```{r eval=FALSE}
# 例如，下面调用的boxplot()函数会展示基于supp特征进行分类后ToothGrowth数据集中len特征的数值分布差异。
boxplot(ToothGrowth$len～as.factor(ToothGrowth$supp), 
        col="blue")
# 在这个例子中，因为supp只有两种值：VC和OJ，所以我们得到了两个箱形图。
```

为了确定分类OJ和VC中观测的相对数目，你可以给boxplot()函数加入参数varwidth=TRUE。这样，箱体的宽度就会与观测数目成比例：

```{r eval=FALSE}
# 在下面的例子中，因为每个分类都有30条观测数据，所以箱体是一样大小的。因此，我们为箱体填充了不同的颜色：
boxplot(ToothGrowth$len～as.factor(ToothGrowth$supp),   
        col=c("blue","orange"), 
        varwidth=TRUE)
```

#### 3.箱型图的信息解读

1.  数据的分布范围

箱型图展示了数据的上方触须（第三四分位数加上1.5倍的IQR）、下方触须（第一四分位数加上1.5倍的IQR）、四分位数以及中位数，这些可以帮助你了解数据的整体分布情况。图中的“箱子”代表了数据的50%分布范围（从第1四分位数Q1到第3四分位数Q3），而箱型图的“须”显示了数据的整体范围。

影响后续分析：如果数据的分布范围较大，可能需要使用数据标准化或变换方法以确保后续分析不会受到异常值或数据范围过大的影响。

2.  中心位置（中位数）

箱型图中的中位数（通常表示为箱子内的线）展示了数据的集中趋势。如果中位数偏离箱子的中心，表明数据可能具有偏态。

影响后续分析：如果数据呈偏态分布，可以考虑使用中位数而不是均值来描述数据中心，或者进行数据的偏态纠正（如对数变换）。

3.  数据的偏态

通过观察箱型图中中位数和箱体的偏移情况，可以判断数据的偏态。例如，如果中位数偏离箱体的中心位置，或者上下须的长度不对称，可能表明数据存在右偏（正偏）或左偏（负偏）。

影响后续分析：数据的偏态可能会影响回归分析、假设检验等，尤其是基于正态性假设的分析方法（如t检验）。可能需要进行数据转化或使用非参数检验方法。

4.  异常值（Outliers）

图中的离群点通常是通过1.5倍四分位距规则（即超过1.5倍IQR的值）标识的。这些值通常被认为是异常值或极端值，可能会对分析结果产生较大影响。

影响后续分析：如果异常值不是数据错误且对分析有显著影响，则应考虑是否需要剔除这些异常值，或者采用**鲁棒方法（如中位数回归）**来减少其影响。

5.  数据的变异性

通过箱型图的箱体高度（即四分位差IQR）可以判断数据的变异性。较高的箱体意味着数据变异性较大。

影响后续分析：较大的数据变异性可能会影响模型的稳定性，可能需要通过数据标准化、增加样本量或调整模型来应对。

### 3 条形图

#### 1.条形图的使用

在条形图中你可以基于位置比较数值。

在这个例子中，我们使用了barplot()和table()函数，用于统计airquality数据集中变量Temp的每一个数值的数量：

```{r eval=FALSE}
# 在这里我们可以看到，Temp值为56的观测有1条，75的有4条，90的有3条：
table(airquality$Temp)
barplot(table(airquality$Temp), col="blue")
```

在条形图中，条的高度等于数值的数量；这意味着只要看一眼你就能知道在任何值下的观测值的数目——在本例中，我们可以快速发现数据集中Temp等于81出现的频率最高。

在数据挖掘项目的EDA阶段，了解数据的分布是十分重要的。

#### 2.条形图和直方图的区别

-   **条形图**：用于显示离散或分类数据的分布或比较，x轴为离散类别。

-   **直方图**：用于展示连续数据的分布形态和集中趋势，x轴为连续的数值区间。

### 4 核密度图

#### 1.核密度图的定义

密度图（density plot）类似于平滑后的直方图。所以除了直方条之外，我们也可以用曲线表示分布的密度。可以使用density()函数在R中计算变量的核密度估计。

-   **核密度估计**（KDE）是一种非参数的方法，用来估计随机变量的概率密度函数。它是通过对观测数据的每一个点进行平滑处理，构造出一个平滑的密度函数。KDE 是直方图的一种改进，能够提供比直方图更平滑、更连续的密度估计。

-   **核密度函数**是指在核密度估计中，使用的平滑函数，也就是我们所说的“核函数”。核函数一般是一个对称的函数，常见的核函数包括高斯核（Gaussian kernel）、均匀核（Uniform kernel）、Epanechnikov核等。核函数的作用是将每个数据点周围的区域平滑为一个光滑的曲线，使得整个数据集的密度估计更加平滑。

#### 2.核密度估计的工作原理

1.  **选择核函数**：对于每个数据点，使用一个核函数来表示其密度，通常选择对称的光滑函数（如高斯核）。

2.  **带宽参数（Bandwidth）**：带宽控制着核函数的平滑程度，即核函数的宽度。如果带宽太小，估计出的密度曲线会出现很多小的波动，导致过拟合；如果带宽太大，密度曲线会过于平滑，失去细节。因此，带宽的选择非常重要。

3.  **构造核密度估计**：将所有数据点的核函数加在一起，得到一个整体的密度估计。这个密度曲线在每个数据点处都有一个平滑的“峰”，整个数据集的核密度估计就是这些核函数的叠加。

公式表达：

$\hat{f}(x) = \frac{1}{n h} \sum_{i=1}^{n} K\left(\frac{x - x_i}{h}\right)$

其中：

-   $\hat{f}(x)$是在点 x 处的估计密度。

-   n 是数据点的数量。

-   h 是带宽参数，控制核函数的平滑程度。

-   K 是核函数（如高斯核）。

-   $x_i$是第 i 个数据点。

#### 3.核密度图使用实例

下例是用airquality数据集中的变量Temp生成的密度图示例：

```{r eval=FALSE}
temp_dens <- density(airquality$Temp)
plot(temp_dens, lwd=3, col="blue")
```

#### 4.核密度图和直方图的区别和联系

-   频率 VS (概率)密度

在统计学中，**密度**和**直方图中的频率**是两个不同的概念（尽管这两类图都可以计算概率密度分布、即直方或曲线投下的面积）：直方图显示的是数据在不同区间内的**频数**；而核密度图则表示的是每个点的**相对密度（这是一个估计概率密度，在区间上计算尚且准确，具体到点就会有误差）**，这意味着密度图展示的是观测值位于某个范围内的比例，而不是确切的数目。例如，密度图描述的是观测值介于0和50之间的**百分比**，而不是具体的频数。

-   边缘处的概率密度

尽管密度图已经通过平滑方法对数据进行了处理，这个过程可能在图的边缘引入一些小的误差，但其整体形状仍然类似于直方图；但核密度图可能会显示出某些边界区域（如50以下或100以上的地方）没有数据（边界处的概率密度为0的情况），但这并不意味着数据在这些区域完全不存在。这是因为密度图是一个平滑的估计。

因此，在解释密度图的边界时，我们要特别小心。

-   核密度图相较于直方图的优点

选择使用**密度图**而不是**直方图**的一个主要优点是：密度图能够在同一张图中叠加多个分布进行比较。

例如，在使用R语言的**ToothGrowth**数据集时，我们可以为变量 `len` 创建一个密度图，并在同一图中叠加第二个密度图，这次只针对 `supp` 值为 `VC` 的数据子集——在代码中，使用 `which()` 函数来筛选出 `supp` 为 `VC` 的观测数据：

```{r eval=FALSE}
# 为变量 len 创建一个密度图
len_dens <- density(ToothGrowth$len)

# 可视化
plot(len_dens, 
     lwd=3, #设置线条的宽度为 3，使得密度曲线更加粗一些
     col="blue")#将密度曲线的颜色设置为蓝色

# 针对supp特征值为VC的len特征的数据子集创建一个密度图
# 使用 which() 函数来筛选出 supp 为 VC 的观测数据
VC_dens <- density(ToothGrowth$len[which(ToothGrowth$supp=="VC")])

# 在同一图中叠加第二个密度图
lines(VC_dens,#lines() 函数将另一条密度曲线添加到现有的图形中
        lwd=3, 
        col="orange")
```

在生成的图中，可以非常清楚地比较整体数据的密度与只包含 `VC` 组数据的密度，发现它们略有不同。

### 5 散点图

#### 1.涉及两个变量的散点图

散点图（scatterplot）在识别变量的视觉关系时十分有用，因此它也是在探索性数据分析阶段最常用的图表。

在下面的R代码中，我们使用plot()函数来实现散点图。使用ToothGrowth数据集中两个定量变量len和dose。

```{r eval=FALSE}
# plot函数的参数pch指定了图中代表数据点的符号，取值为19代表实心圆，也有其他很多符号可供选择。
plot(ToothGrowth$len, ToothGrowth$dose, pch=19, col="blue")
# 在R帮助中，?pch可以说明其他选项：
?pch

# 图中x轴是变量len，y轴是变量dose。图中的每个点表示一条观测记录。从图中我们可以看到，dose的值是离散的，即0.5、1.0和2.0。
# 在以这种形式展现的数据中，你总是能马上发现特征。这种特征有助于了解数据：我们能很快发现的一个特点是：随着剂量增加，牙齿的长度也随之增加。
```

注意，在R的散点图中，如果数据集中有NA值（缺失值），R不会画出这个点。如果你在探究阶段没有分析并处理缺失值的话，可能会得出一些错误的结论。

#### 2.涉及三个变量的散点图：二维

在散点图的帮助下，你也可以使用col和pch参数在图中展示第3个变量：

例如，col可以用不同的数据点颜色展示不同的数值——当supp的值为“VC”时，我们可以将数据点标成红色，当supp的值为“OJ”时，可以将数据点标为蓝色。这意味着我们可以把3个变量展现在同一个二维图表中。

或者，用pch为每个数据点分配不同的形状——如下面给出的R代码：若supp值为“VC”，将pch置为0（即空心方形）；若supp值为“OJ”，将pch置为1（即空心圆形）。

```{r eval=FALSE}
plot(ToothGrowth$len, ToothGrowth$dose,
     # ifelse()是一个条件判断函数（并不具备索引函数的作用），它的语法是：ifelse(条件, 条件为真时的值, 条件为假时的值)
     pch=ifelse(ToothGrowth$supp=="VC",0,1),
     col="blue")
```

#### 3.涉及三个变量的散点图：三维

另一个散点图的示例涉及scatterplot3d包的使用，它能在一个三维图中展示变量间的三维关系。下面是示例的R代码，使用airquality数据集，变量Solar.R为x 轴，Wind为y 轴，Temp为z 轴。

```{r eval=FALSE}
library(scatterplot3d)
scatterplot3d(airquality$Solar.R, 
              airquality$Wind,
              airquality$Temp, 
              highlight.3d=TRUE, 
              col.axis="blue", 
              col.grid="lightblue",
              main="Air Quality Data Set",
              pch=20,
              xlab="Solar Radiation",
              ylab="Wind",
              zlab="Temp")
```

#### 4.基于相关矩阵的散点图

##### 相关性分析

相关性指的是任何一类广泛的统计关系都涉及到的依赖关系。相关矩阵将变量组合在一起，计算每每两个变量之间的相关性。

计算一个数据集中**定量变量的相关矩阵**，然后**绘制一张散点图矩阵**来目测相关性，这是一项很有价值的工作。R中的cor()函数可以用来计算相关矩阵；在R的cor函数中，默认使用的是Pearson相关性，不过，通过改变method参数，也可以使用Kendall法或Spearman法计算。

让我们使用iris数据集来演示这一技巧：

```{r eval=FALSE}
# 我们看到Sepal.Length和Petal.Width的相关性是81.8%，这说明了它们之间的相关性较强。
# 更进一步，Petal.Length和Petal.Width之间达到了更高的相关性，即96.3%。
cor(iris[,c(1,2,3,4)], method="pearson")
```

##### 基于相关性的散点图可视化

现在使用pairs()函数对相关性进行散点图可视化：我们可以用“相关矩阵+散点图”对相关性进行定量展示。

```{r eval=FALSE}
# 看看变量Petal.Length和Petal.Width的子图，这两个变量的图表展示了一个非常明显的趋势：随着Petal.Width的增加，Petal.Length也会增加
# 在另一方面，变量Sepal.Length和Sepal.Width展现出-11.7%的负相关
pairs(iris[,c(1,2,3,4)])
```

上述分析结果可以帮助你进行后面的监督机器学习。

##### 大数据项目的探索性分析利器：散点图实战

我们将在基于海量数据的大数据机器学习项目中看看散点图在探索性数据分析中的效果。为此，我们将使用一个大型仿真数据集：在下面的R代码中，我们使用了rnorm()函数生成了两组正态分布的随机数（每组100000条数据）——它基本上是一大团点，这对于大型数据集来说很常见，因为大多数的点叠加在一起，不可能知道图表密集的中间部分发生了什么；具体地说，你无法确定点的密度，即点可能处于哪一块确定的区域。

```{r eval=FALSE}
# 生成一个包含 100,000 个数据点的正态分布随机数，并赋值给变量 x
  # 1e5是科学计数法的写法，意思是1×10^5也就是100000。
x <- rnorm(1e5)
# 生成一个包含 100,000 个数据点的正态分布随机数，并赋值给变量 y。
# rnorm(n, mean = 0, sd = 1)用于生成来自正态分布的随机数，其基本语法是：
  # n：生成的随机数的个数。
  # mean：正态分布的均值，默认值是 0。
  # sd：正态分布的标准差，默认值是 1。
y <- rnorm(1e5)
# 将 x 和 y 的值作为散点图的横纵坐标，pch=16 表示使用实心圆点来绘制这些数据点
plot(x,y, pch=16)
```

综上，我们需要使用其他工具（配合散点图）来探究数据的特点：

-   **抽样+散点图**

一种技巧是对数据集中的数值进行取样：在下面的R代码中，使用sample()函数抽取1000条不重复的随机数据，生成一个整型向量当做x和y指标。由于我们的目标是用肉眼观察一千个数据点，使用plot()。

我们用sampledSubset作为索引获取x和y对应的值：现在数据点易分辨得多了，因为我们处理的是原始数据集中的一小部分随机子样本，也可以看到两个变量之间的关系。**对于探索性数据分析来说，你不必看到所有的数据点**。

```{r eval=FALSE}
sampledSubset <- sample(1:1e5, 
                        size=1000, 
                        replace=FALSE)
plot(x[sampledSubset], 
     y[sampledSubset], 
     pch=16)
```

-   **散点图+核密度估计+箱方图法**

另一种处理海量数据点的方法是使用smoothScatter()函数，它能通过核密度估计获取一个代表散点图的彩色平滑密度：在这个例子中，我们使用整个仿真数据集。数据点越多的地方，颜色越深。

注意，离中心越近，数据点越多；异常值以实心点的形式展示，它们分布在图的边缘。所以你不用看到所有的数据点，一张平滑散点图就能帮助你了解数据之间的关系。

```{r eval=FALSE}
smoothScatter(x,y)
```

最后，我们使用一个叫“六边形箱”的工具来展示一个数据集中的大量数据点：

```{r eval=FALSE}
# install.packages("hexbin")
library(hexbin)
# 使用hexbin包根据x和y创建hexbin对象
hbins <- hexbin(x,y)
# 将x和y的值分解为六边形箱，然后计算每个箱中数据点的数目
plot(hbins)
```

同理，图中深色的箱子意味着更多的数据点，而外部浅色的箱子意味着较少的数据点。在有大量数据点的情况下，使用箱方法能帮助你观察x和y之间的关系。

### 6 QQ图

#### 1.QQ图的定义

QQ图(quantile- quantile plot)、或称作分位数-分位数图：**因为都用于定量变量，这种图在某些方面和散点图比较相似**，区别在于这种图用一个变量的分位数-另一个变量的分位数来作图，用于目测两个变量之间潜在的分布相似性；图中的坐标轴代表变量的第一分位数一直到第一百分位数。

在下面的R代码中，我们使用了一个只有50个数据点的小型仿真数据集和两个变量x和y：如果这两个变量分布相同，你可以预测分位数准确地落在图中abline()函数画出的那条线上（截距为0，斜率为1/这个线的截距和斜率参数是基于标准正态分布的参数设置的：均值为0、标准差为1的标准正态分布）；然而，在下图中我们看到一些差异，比如图的顶部y的分位数可能（因为是随机生成的数据集嘛）比x的分位数要大。

```{r eval=FALSE}
x <- rnorm(50)
y <- rnorm(50)
qqplot(x,y)
abline(c(0,1))
```

**QQ图对于观察数据集是否正态分布十分有用**。

#### 2.QQ图的原理和价值

##### 数据抽屉

+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **概念**               | **解释**                                                                                                                                                                                                     |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **（实际分布）分位数** | 数据按从小到大的顺序排列，分位数表示数据集中特定百分比位置的值。例如，第 25 百分位数是数据集的第 25%位置的值。                                                                                               |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **理论分布的分位数**   | 选择一个假设的理论分布（如正态分布），并计算该分布的各个分位数。这些分位数代表了理论分布在特定百分比位置的值。                                                                                               |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **QQ图的作用**         | 用于比较数据分布与理论分布（如正态分布）是否一致，帮助识别数据的分布特性、异常值、尾部行为等。                                                                                                               |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **原理**               | 1\. 在QQ图中，我们选择一个假设的理论分布（例如正态分布），并根据该分布计算出其各个分位数。这些分位数代表了理论分布在特定百分比位置的值。例如，对于标准正态分布，它的分位数由累积分布函数（CDF）定义[1]。     |
|                        |                                                                                                                                                                                                              |
|                        | 2\. 将数据集的实际分位数与理论分布的分位数进行逐一比较。如果数据遵循某个理论分布，数据的分位数应该与该理论分布的分位数非常接近，并且在图上形成一条直线。                                                     |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **如何解释QQ图？**     | **数据点与直线一致的意义：**                                                                                                                                                                                 |
|                        |                                                                                                                                                                                                              |
|                        | 数据分布与理论分布（如正态分布）相符，数据点在QQ图中接近直线，表明数据可能符合正态分布或其他假设分布。                                                                                                       |
|                        |                                                                                                                                                                                                              |
|                        | **数据点偏离直线的含义：**                                                                                                                                                                                   |
|                        |                                                                                                                                                                                                              |
|                        | 1、**尾部偏离**：数据点在图的两端偏离直线，通常表示数据的尾部（分布的极端部分）比理论分布更重（厚尾分布，极端值较多，如t分布）或更轻（轻尾分布，极端值较少），这种情况可能意味着数据的分布具有较大的极端值： |
|                        |                                                                                                                                                                                                              |
|                        | -   **轻尾分布**：如果数据点在图的两端比直线更加平缓，说明数据可能是轻尾分布（如均匀分布）。                                                                                                                 |
|                        |                                                                                                                                                                                                              |
|                        | -   **厚尾分布**：如果数据点在图的两端向外延伸，表明数据可能是厚尾分布（如 t 分布）。                                                                                                                        |
|                        |                                                                                                                                                                                                              |
|                        | 2、**中心偏离**：如果数据点在图的中间偏离直线，通常说明数据的分布有偏态；数据点偏离图的中间，可能存在偏态（右偏或左偏）。                                                                                    |
|                        |                                                                                                                                                                                                              |
|                        | 3、弯曲：如果数据点在 QQ 图中形成弯曲而不是直线，数据分布与理论分布不同（数据的分布可能不是正态分布）。                                                                                                      |
|                        |                                                                                                                                                                                                              |
|                        | **异常值识别**：                                                                                                                                                                                             |
|                        |                                                                                                                                                                                                              |
|                        | 在QQ图中，离群点会明显偏离理论分布的直线，可能是数据中的异常值。通过QQ图，异常值可以被识别并进一步检查。                                                                                                     |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **QQ图揭示的结论**     | -   数据是否符合正态分布或其他理论分布。                                                                                                                                                                     |
|                        |                                                                                                                                                                                                              |
|                        | -   数据是否具有偏态或重尾、轻尾等特征。                                                                                                                                                                     |
|                        |                                                                                                                                                                                                              |
|                        | -   异常值（极端值）的识别。                                                                                                                                                                                 |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **如何帮助后续分析**   | -   **数据预处理**：                                                                                                                                                                                         |
|                        |                                                                                                                                                                                                              |
|                        |     -   如果数据不符合正态分布，可能需要对数据进行变换（如对数变换、平方根变换等），或者考虑使用非参数方法来进行后续分析。                                                                                   |
|                        |                                                                                                                                                                                                              |
|                        |     -   如果数据明显偏离正态分布，可能意味着需要使用鲁棒的统计方法来减少对正态性假设的依赖。                                                                                                                 |
|                        |                                                                                                                                                                                                              |
|                        | -   **模型选择**：                                                                                                                                                                                           |
|                        |                                                                                                                                                                                                              |
|                        |     -   如果数据符合正态分布，很多统计模型（如线性回归、t 检验等）假设数据服从正态分布，可以使用这些模型进行数据分析。                                                                                       |
|                        |                                                                                                                                                                                                              |
|                        |     -   如果数据不符合正态分布，则需要选择其他模型（如决策树、随机森林等），或进行数据转换，使数据更接近正态分布。                                                                                           |
|                        |                                                                                                                                                                                                              |
|                        | -   **假设检验**：                                                                                                                                                                                           |
|                        |                                                                                                                                                                                                              |
|                        |     -   许多假设检验（如正态性检验）都依赖于数据是否符合正态分布。通过QQ图可以帮助我们判断是否需要进行这些假设检验，以及选择合适的检验方法。                                                                 |
|                        |                                                                                                                                                                                                              |
|                        | -   **异常值处理**：                                                                                                                                                                                         |
|                        |                                                                                                                                                                                                              |
|                        |     -   在数据挖掘中，异常值可能会影响模型的准确性。QQ图可以帮助识别异常值，并决定是否要去除或处理这些异常值。                                                                                               |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **QQ图的有效性**       | QQ图有效因为它通过逐一对比数据的分位数与理论分布的分位数，揭示了数据是否符合理论分布，偏离直线的情况可以反映数据的分布特性。                                                                                 |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **QQ图的实际应用**     | -   用于判断数据是否符合正态分布，帮助选择合适的统计模型或变换方法。                                                                                                                                         |
|                        |                                                                                                                                                                                                              |
|                        | -   数据是否具有偏态或重尾、轻尾等特征。                                                                                                                                                                     |
|                        |                                                                                                                                                                                                              |
|                        | -   识别数据中的异常值（极端值）。                                                                                                                                                                           |
|                        |                                                                                                                                                                                                              |
|                        | -   进行假设检验时验证数据的分布假设。                                                                                                                                                                       |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

##### 注释

**[1]** CDF（累积分布函数）和 PDF（概率密度函数）

| **概念** | **PDF（概率密度函数）** | **CDF（累积分布函数）** |
|----|----|----|
| **定义** | 描述随机变量在某个点处的概率密度（连续型随机变量）。 | 描述随机变量小于或等于某个值的累计概率。 |
| **公式** | $f_X(x) = \frac{d}{dx} F_X(x)$ | $F_X(x) = \int_{-\infty}^{x} f_X(t) dt$ |
| **计算方法** | 通过导数计算。 | 通过积分计算。 |
| **值的范围** | 取值范围为非负，且总积分为 1。 | 取值范围在 [0, 1] 之间。 |
| **直观理解** | PDF 描述每个点的概率密度（概率区间），不能直接给出具体某个点的概率。 | CDF 给出数据小于或等于某个值（一段区间内）的累计概率。 |
| **关系** | PDF 是 CDF 的导数，CDF 是 PDF 的积分（的一种特殊形式）。 | CDF 是通过积分 PDF 得到的，PDF 是通过对 CDF 求导得到的。 |

PDF 和 CDF 是描述随机变量分布的两个重要函数。PDF 给出每个点的概率密度，而 CDF 描述的是随机变量小于或等于某个特定值的累计概率。它们之间通过导数和积分相互联系，CDF 是 PDF 的积分函数的一种特殊形式。

CDF的作用如下：

-   **计算概率**：CDF 可以用来计算某个值范围内的概率。例如，给定一个随机变量的 CDF，想要知道 XXX 落在区间[a, b]内的概率，可以用：

    $P(a \leq X \leq b) = F(b) - F(a)$

-   **检验分布**：CDF 可用于对比数据的实际分布与理论分布。例如，QQ图就是通过比较数据的样本分位数与理论分布的分位数来检验数据是否符合特定分布。

-   **描述数据分布**：CDF 可以提供一个直观的方式来查看随机变量的分布，帮助识别数据的集中趋势、分布的形态（如偏态、峰度等），以及尾部行为。

PDF的作用如下：

| **应用领域** | **应用描述** |
|----|----|
| **数据分布描述** | 通过 PDF 理解数据的分布形态、估计数据的均值、方差、偏度和峰度等分布特征。 |
| **概率计算** | 使用 PDF 计算区间内的概率、尾部概率等，常用于风险管理、决策分析等领域。 |
| **参数估计与模型拟合** | PDF 是最大似然估计（MLE）和分布拟合的基础，帮助我们从数据中估计参数并选择最适合的概率分布模型。 |
| **假设检验** | 在统计推断中，PDF 用于计算 p 值和检验假设，如 t 检验、卡方检验等。 |
| **生成随机变量与模拟** | 在模拟和仿真中，通过 PDF 生成符合特定分布的随机变量，常用于蒙特卡洛模拟等应用。 |
| **风险管理与决策分析** | PDF 用于计算尾部风险、极端事件发生的概率，帮助决策者管理风险并制定策略。 |
| **机器学习与数据挖掘** | PDF 被用在生成式模型、决策树等机器学习算法中，帮助分析和预测数据的分布和类别。 |
| **图像处理与信号处理** | PDF 用于建模噪声、图像灰度分布等，帮助在图像处理和信号处理任务中进行滤波与分割。 |

**[2] QQ图的几种情况**

![QQ图的几种情况](F:\R-File\Learning%20Record%20For%20R\2-Data%20Science%20And%20R\2-PROJECTS%20(Code%20Notes)\attachment\QQ图示例.png)

-   理想情况 - 符合正态分布：当数据点几乎完全落在理论直线上时，表明数据很好地符合假设的分布（通常是正态分布）。这种情况下，样本数据的分位数与理论分布的分位数一致。

-   厚尾分布：当数据点在图的两端向外延伸，尤其是在尾部区域偏离理论直线时，表明数据具有比正态分布更重的尾部，即极端值出现的频率更高。常见的厚尾分布包括t分布、柯西分布等。在图中可以看到，数据点在两端比理论线向外弯曲。

-   轻尾分布：当数据点在图的两端向内收缩，接近水平，表明数据具有比正态分布更轻的尾部，极端值出现的频率较低。均匀分布是典型的轻尾分布。图中显示数据点在两端比理论线更加平缓。

-   左偏分布：当数据点形成S形曲线，上部向内收缩，下部向外延伸，表明分布有左偏（负偏）特性。这意味着分布有一条长尾延伸到左侧，中位数大于平均数。

-   右偏分布：当数据点形成S形曲线，上部向外延伸，下部向内收缩，表明分布有右偏（正偏）特性。这意味着分布有一条长尾延伸到右侧，平均数大于中位数。

-   含异常值的分布：异常值在QQ图中表现为明显偏离理论直线的点，通常出现在图的极端位置。在图中，最右侧的数据点明显偏离了其他点所形成的趋势，可能代表了一个潜在的异常值。

### 7 热图

热图（heatmap）有点类似于二维的直方图，R中的热图函数：image()。热图构思是使用色彩亮度来展示一个数据值的大小，所以，颜色越亮，值越大：白色对应最大值，红色对应最小值，中间的渐变色代表了中间的其他值。在热图的帮助下，你可以在一张图中看到整个矩阵。

让我们用iris数据集画一张热图，在这个例子中，数据集为中等大小，所以我们将使用全部150行观测数据和所有的4个定量变量绘制热图。R代码如下所示：

```{r eval=FALSE}
# 第一个参数代表用于图表中的矩阵行（观测行），第二个参数指的是特征变量。第三个参数需要是一个矩阵对象，所以我们将iris数据框用as.matrix()函数转换为矩阵的形式。
image(1:150, 
      1:4, 
      as.matrix(iris[1:150, 1:4]))
```

上图展示了生成的热图，其中行4的值最小，行1的值最大。

在看热图的过程中，要注意图的顺序是颠倒的。也就是说，图中的行相当于特征变量，列相当于观测值，这可能有点违反直觉——因为我们在image()函数调用中一般先指定行再指定列。当然，如果你愿意的话，你可以用下面的R代码对矩阵进行转置：

```{r eval=FALSE}
# 这行代码从 iris 数据集的前 150 行和前 4 列中提取数据，并将其转换为一个矩阵。
transMatrix <- as.matrix(iris[1:150, 1:4])
# t(transMatrix)：t() 函数是转置操作，将矩阵的行和列互换，即行变列，列变行。
# [, nrow(transMatrix):1]：这部分代码反转了矩阵的列顺序，nrow(transMatrix) 获取矩阵的行数，然后通过 nrow(transMatrix):1 创建一个从行数（最后一行）到 1 的序列，表示对列的反转。
transMatrix <- t(transMatrix)[,nrow(transMatrix):1]
image(1:4, 1:150, transMatrix)
```

### 8 箱型图：探索缺失值成因（将缺失值与否作为分组依据）

我们要讨论的最后一种探索性图表又是箱形图，因为可以借助箱形图来分析数据集中缺失值（NA）与其他变量之间的关系。

例如：我们使用 airquality 数据集中的变量 Solar.R 和 Temp 来探究 Solar.R 的缺失值是否与 Temp 的值有关。如下图所示，可以发现当Solar.R值为NA时，Temp的值普遍更小；当Solar.R值不为NA时，Temp的值普遍更大。

```{r eval=FALSE}
# is.na(airquality$Solar.R)会生成一个逻辑向量(TRUE或FALSE，即对应位置是缺失值的返回True，对应位置不是缺失值返回False)，指示Solar.R是否为NA——箱形图会根据Solar.R是否为NA对Temp的值进行分组并绘制两个箱形图。
boxplot(airquality$Temp～is.na(airquality$Solar.R))
```

除了箱形图，还有许多其他方法可以探索缺失值与数据分布之间的关系：

1.  **热图（Heatmap）**：可以使用热图可视化数据中的缺失值，帮助识别缺失模式和关联。

2.  **散点图**：可以通过散点图显示缺失值和其他变量之间的关系，帮助发现变量间的潜在相关性。

3.  **缺失值模式分析**：一些专门的工具（如 R 包 `mice`）可以用来分析缺失值的模式，判断缺失值是否随机，是否有系统性原因。

### 9 解释性图表

相比于上面提到的探索性图表，解释性图表要更正式、更固定。此外，这种图用于跟其他人交流结果。要对探索性图表进行数次迭代，才能生成一张解释性图表。

探索性图表用于发现数据中的隐藏信息，而解释性图表用于传达数据的故事，并且它们常常进入机器学习项目的最终报告和结果中，因为这些图表是项目最终记录的一部分，你需要美化标题、标签、图例等。下面是解释性图表常见的一些目标：

-   总体目标是传递信息。
-   信息密度需要达到一定的水平，即用语言不可能解释结果。
-   尺寸和颜色不但要传递信息，也要有美学方面的考虑。
-   这些图表应该包含大号且易于理解的标题、坐标轴和图例。

让我们看一个使用airquality数据集的详细例子，R代码如下所示。

我们的目标是生成有两个面板的一个解释性图表。R可以以多种方式堆积面板：使用par(mfrow=c(1,2))函数，我们可以得到一行两列的面板，所以图表将会并排出现。

然后我们使用变量Ozone的直方图画出第一个面板；用xlab参数在x轴加上标签（不用R描述，它是默认使用的），用main参数为图表加上标题。

第二个图表是变量Ozone和Temp的散点图：我们用一些特殊的特征，例如用cex参数将数据点进行放大（为了更易辨别），同时我们也用描述性的文本对坐标轴和单位进行标记——在解释性图表中，对所有坐标轴的单位进行标注是很重要的。

最后，我们用legend()函数在图中添加一个简单的图例：注意，legend()出现在左上角坐标轴上，那里是legend框根据前两个参数确定的位置。

得到的解释性图表如下图所示：

```{r eval=FALSE}
# mfrow=c(1,2) 表示将图形窗口分成 1 行 2 列，意味着将同时显示两个图形。
par(mfrow=c(1,2))

# xlab="Ozone (ppb)"：X 轴标签为 "Ozone (ppb)"，表示臭氧的浓度，单位为 ppb。
# col="blue"：设置直方图的颜色为蓝色。
# main="Ozone Frequencies"：图形的标题为 "Ozone Frequencies"。
hist(airquality$Ozone, 
     xlab="Ozone (ppb)", 
     col="blue", 
     main="Ozone Frequencies")


plot(airquality$Ozone, 
     airquality$Temp, 
     pch=16, #pch=16：设置点的类型为实心圆（16 表示实心圆）。
     col="blue",#col="blue"：设置点的颜色为蓝色。
     cex=1.25,#cex=1.25：设置点的大小为 1.25 倍默认大小。
     xlab="Ozone (ppb)",#xlab="Ozone (ppb)"：X 轴标签为 "Ozone (ppb)"，表示臭氧浓度。
     ylab="Temperature (degrees F)",#Y 轴标签为 "Temperature (degrees F)"，表示温度。
     main="Air Quality - Ozone vs. Temp",#图形标题为 "Air Quality - Ozone vs. Temp"。
     cex.axis=1.5)#设置坐标轴刻度标签的大小为 1.5 倍默认大小。

# legend(125, 60, ...)：在坐标位置 (125, 60) 处添加图例，指定 legend="May-Sep 1973" 作为图例文本。
legend(125,60,
       legend="May-Sep 1973", 
       col="blue", 
       pch=16, 
       cex=1.0)#cex=1.0：图例的字体大小为默认大小。
```

在 R 中，函数 `legend()` 会默认添加到当前活动的图形中，如果你没有显式指定图形区域，它会在最近的图形区域中添加图例。R 会根据你当前的图形设备（如屏幕或文件）自动确定图形的目标，因此如果你没有特别的 `plot` 设置，R 会假定你是要在当前活动的图形上添加图例，具体原理如下：

1.  **图形设备**：在 R 中，每次调用 `plot()` 都会打开一个新的图形设备（例如一个窗口或图形区域）。你绘制的第二个图（`plot()`）会成为当前活动的图形，而 `legend()` 会在这个活动图形上添加图例。

2.  **顺序执行**：R 是按顺序执行命令的，`plot()` 创建了图形，紧接着的 `legend()` 就会添加到这个图形上。因此，R 会知道 `legend()` 是针对 `plot()` 创建的散点图的。

R 是通过图形设备的顺序管理图形的，legend() 会自动被添加到最后一个绘制的图形中，除非你显式指定其他的目标图形区域。
